# å¿«é€Ÿå¼€å§‹æŒ‡å— / Quick Start Guide

<div align="right">
  <strong>ä¸­æ–‡</strong> | <a href="#english-version">English</a>
</div>

---

## ä¸­æ–‡ç‰ˆ

### ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨5åˆ†é’Ÿå†…å¼€å§‹ä½¿ç”¨æˆ‘ä»¬çš„çš®è‚¤ç—…å˜åˆ†ç±»æ¨¡å‹ã€‚

### ğŸ“‹ å‰ç½®è¦æ±‚

- Python 3.8+
- CUDA 11.0+ (å¦‚æœä½¿ç”¨GPU)
- è‡³å°‘8GB RAM
- è‡³å°‘4GB GPUæ˜¾å­˜ (æ¨è)

### âš¡ å¿«é€Ÿå®‰è£…

#### æ­¥éª¤1: å…‹éš†ä»“åº“

```bash
git clone https://github.com/HeroZyy/skin-lesion-classification.git
cd skin-lesion-classification
```

#### æ­¥éª¤2: åˆ›å»ºç¯å¢ƒ

```bash
# ä½¿ç”¨conda (æ¨è)
conda create -n skin_lesion python=3.8
conda activate skin_lesion

# æˆ–ä½¿ç”¨venv
python -m venv skin_lesion_env
source skin_lesion_env/bin/activate  # Linux/Mac
# skin_lesion_env\Scripts\activate  # Windows
```

#### æ­¥éª¤3: å®‰è£…ä¾èµ–

```bash
# å®‰è£…PyTorch (æ ¹æ®æ‚¨çš„CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CPU only
# pip install torch torchvision

# å®‰è£…å…¶ä»–ä¾èµ–
pip install timm scikit-learn pandas numpy matplotlib seaborn pillow opencv-python tqdm
```

#### æ­¥éª¤4: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†

1. è®¿é—® [Google Drive](https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q)
2. ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶ï¼š
   - **é¢„è®­ç»ƒæ¨¡å‹**: `HAM10000_best_model.pth` (æ¨èï¼Œ98.90%å‡†ç¡®ç‡)
   - **æ•°æ®é›†** (å¯é€‰): `BCN20000.zip` å’Œ/æˆ– `HAM10000.zip`

3. åˆ›å»ºç›®å½•å¹¶æ”¾ç½®æ–‡ä»¶ï¼š

```bash
# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch
# å°†ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶ç§»åŠ¨åˆ°ä¸Šè¿°ç›®å½•

# åˆ›å»ºæ•°æ®é›†ç›®å½•ï¼ˆå¦‚æœéœ€è¦è®­ç»ƒæˆ–æµ‹è¯•ï¼‰
mkdir -p linux_sub/app/datasets
# è§£å‹æ•°æ®é›†åˆ°ä¸Šè¿°ç›®å½•
```

**ç›®å½•ç»“æ„**:
```
linux_sub/app/
â”œâ”€â”€ models/five_model_comparison_final/models/swin_dual_branch/
â”‚   â””â”€â”€ HAM10000_best_model.pth
â””â”€â”€ datasets/
    â”œâ”€â”€ BCN20000/
    â”‚   â”œâ”€â”€ images/
    â”‚   â””â”€â”€ metadata.csv
    â””â”€â”€ HAM10000/
        â”œâ”€â”€ images/
        â””â”€â”€ metadata.csv
```

### ğŸ” å¿«é€Ÿæ¨ç†

åˆ›å»ºæ–‡ä»¶ `quick_inference.py`:

```python
import torch
from PIL import Image
from torchvision import transforms
from models.model_loader import ModelLoader

# 1. åŠ è½½æ¨¡å‹
print("åŠ è½½æ¨¡å‹...")
loader = ModelLoader()
model = loader.load_swin_dual_model("HAM10000", best=True)
model.eval()

# 2. åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
image_path = "your_image.jpg"  # æ›¿æ¢ä¸ºæ‚¨çš„å›¾åƒè·¯å¾„
print(f"åŠ è½½å›¾åƒ: {image_path}")
image = Image.open(image_path).convert('RGB')

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                       std=[0.229, 0.224, 0.225])
])
image_tensor = transform(image).unsqueeze(0)

# 3. æ¨ç†
print("è¿›è¡Œé¢„æµ‹...")
with torch.no_grad():
    output = model(image_tensor)
    probabilities = torch.softmax(output, dim=1)
    prediction = output.argmax(dim=1).item()
    confidence = probabilities.max().item()

# 4. æ˜¾ç¤ºç»“æœ
class_names = ['NV', 'MEL', 'BKL', 'BCC', 'AKIEC', 'VASC', 'DF']
class_descriptions = {
    'NV': 'è‰¯æ€§ç—£',
    'MEL': 'é»‘è‰²ç´ ç˜¤ âš ï¸',
    'BKL': 'è‰¯æ€§è§’åŒ–ç—…',
    'BCC': 'åŸºåº•ç»†èƒç™Œ',
    'AKIEC': 'å…‰åŒ–æ€§è§’åŒ–ç—…',
    'VASC': 'è¡€ç®¡ç—…å˜',
    'DF': 'çš®è‚¤çº¤ç»´ç˜¤'
}

print("\n" + "="*50)
print(f"é¢„æµ‹ç»“æœ: {class_names[prediction]} - {class_descriptions[class_names[prediction]]}")
print(f"ç½®ä¿¡åº¦: {confidence:.2%}")
print("="*50)
print("\næ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
for name, prob in zip(class_names, probabilities[0]):
    bar = "â–ˆ" * int(prob * 50)
    print(f"{name:6s} {prob:.2%} {bar}")
```

è¿è¡Œï¼š

```bash
python quick_inference.py
```

### ğŸ“Š é¢„æœŸè¾“å‡º

```
åŠ è½½æ¨¡å‹...
åŠ è½½å›¾åƒ: your_image.jpg
è¿›è¡Œé¢„æµ‹...

==================================================
é¢„æµ‹ç»“æœ: MEL - é»‘è‰²ç´ ç˜¤ âš ï¸
ç½®ä¿¡åº¦: 97.85%
==================================================

æ‰€æœ‰ç±»åˆ«æ¦‚ç‡:
NV     1.23% â–Œ
MEL    97.85% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
BKL    0.45% 
BCC    0.32% 
AKIEC  0.08% 
VASC   0.05% 
DF     0.02% 
```

### ğŸ¯ ä¸‹ä¸€æ­¥

1. **æŸ¥çœ‹å®Œæ•´æ–‡æ¡£**: [README.md](README.md)
2. **äº†è§£æ¨¡å‹è¯¦æƒ…**: [MODEL_DOWNLOAD_GUIDE.md](MODEL_DOWNLOAD_GUIDE.md)
3. **å­¦ä¹ å®Œæ•´æ•™ç¨‹**: [COMPLETE_TUTORIAL.md](COMPLETE_TUTORIAL.md)
4. **å¯¹æ¯”SOTAæ–¹æ³•**: [COMPARISON_WITH_SOTA.md](COMPARISON_WITH_SOTA.md)

### ğŸ’¡ æç¤º

- **æ¨èä½¿ç”¨HAM10000æ¨¡å‹**: å‡†ç¡®ç‡98.90%ï¼Œæ€§èƒ½æœ€ä½³
- **GPUåŠ é€Ÿ**: ä½¿ç”¨GPUå¯æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦
- **æ‰¹é‡å¤„ç†**: å¯ä»¥ä¸€æ¬¡å¤„ç†å¤šå¼ å›¾åƒä»¥æé«˜æ•ˆç‡

### ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

- **æ–‡æ¡£**: æŸ¥çœ‹ [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)
- **é—®é¢˜**: æäº¤ [GitHub Issue](https://github.com/HeroZyy/skin-lesion-classification/issues)
- **é‚®ä»¶**: a1048666899@gmail.com

---

<div id="english-version"></div>

## English Version

### ğŸš€ 5-Minute Quick Start

This guide will help you get started with our skin lesion classification model in 5 minutes.

### ğŸ“‹ Prerequisites

- Python 3.8+
- CUDA 11.0+ (if using GPU)
- At least 8GB RAM
- At least 4GB GPU VRAM (recommended)

### âš¡ Quick Installation

#### Step 1: Clone Repository

```bash
git clone https://github.com/HeroZyy/skin-lesion-classification.git
cd skin-lesion-classification
```

#### Step 2: Create Environment

```bash
# Using conda (recommended)
conda create -n skin_lesion python=3.8
conda activate skin_lesion

# Or using venv
python -m venv skin_lesion_env
source skin_lesion_env/bin/activate  # Linux/Mac
# skin_lesion_env\Scripts\activate  # Windows
```

#### Step 3: Install Dependencies

```bash
# Install PyTorch (choose based on your CUDA version)
# CUDA 11.8
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# CPU only
# pip install torch torchvision

# Install other dependencies
pip install timm scikit-learn pandas numpy matplotlib seaborn pillow opencv-python tqdm
```

#### Step 4: Download Pre-trained Models and Datasets

1. Visit [Google Drive](https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q)
2. Download the following files:
   - **Pre-trained model**: `HAM10000_best_model.pth` (recommended, 98.90% accuracy)
   - **Datasets** (optional): `BCN20000.zip` and/or `HAM10000.zip`

3. Create directories and place files:

```bash
# Create model directory
mkdir -p linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch
# Move downloaded model file to the above directory

# Create datasets directory (if you need to train or test)
mkdir -p linux_sub/app/datasets
# Extract datasets to the above directory
```

**Directory Structure**:
```
linux_sub/app/
â”œâ”€â”€ models/five_model_comparison_final/models/swin_dual_branch/
â”‚   â””â”€â”€ HAM10000_best_model.pth
â””â”€â”€ datasets/
    â”œâ”€â”€ BCN20000/
    â”‚   â”œâ”€â”€ images/
    â”‚   â””â”€â”€ metadata.csv
    â””â”€â”€ HAM10000/
        â”œâ”€â”€ images/
        â””â”€â”€ metadata.csv
```

### ğŸ” Quick Inference

Create file `quick_inference.py`:

```python
import torch
from PIL import Image
from torchvision import transforms
from models.model_loader import ModelLoader

# 1. Load model
print("Loading model...")
loader = ModelLoader()
model = loader.load_swin_dual_model("HAM10000", best=True)
model.eval()

# 2. Load and preprocess image
image_path = "your_image.jpg"  # Replace with your image path
print(f"Loading image: {image_path}")
image = Image.open(image_path).convert('RGB')

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                       std=[0.229, 0.224, 0.225])
])
image_tensor = transform(image).unsqueeze(0)

# 3. Inference
print("Making prediction...")
with torch.no_grad():
    output = model(image_tensor)
    probabilities = torch.softmax(output, dim=1)
    prediction = output.argmax(dim=1).item()
    confidence = probabilities.max().item()

# 4. Display results
class_names = ['NV', 'MEL', 'BKL', 'BCC', 'AKIEC', 'VASC', 'DF']
class_descriptions = {
    'NV': 'Melanocytic Nevi (Benign)',
    'MEL': 'Melanoma (Malignant) âš ï¸',
    'BKL': 'Benign Keratosis',
    'BCC': 'Basal Cell Carcinoma',
    'AKIEC': 'Actinic Keratoses',
    'VASC': 'Vascular Lesions',
    'DF': 'Dermatofibroma'
}

print("\n" + "="*50)
print(f"Prediction: {class_names[prediction]} - {class_descriptions[class_names[prediction]]}")
print(f"Confidence: {confidence:.2%}")
print("="*50)
print("\nAll Class Probabilities:")
for name, prob in zip(class_names, probabilities[0]):
    bar = "â–ˆ" * int(prob * 50)
    print(f"{name:6s} {prob:.2%} {bar}")
```

Run:

```bash
python quick_inference.py
```

### ğŸ“Š Expected Output

```
Loading model...
Loading image: your_image.jpg
Making prediction...

==================================================
Prediction: MEL - Melanoma (Malignant) âš ï¸
Confidence: 97.85%
==================================================

All Class Probabilities:
NV     1.23% â–Œ
MEL    97.85% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
BKL    0.45%
BCC    0.32%
AKIEC  0.08%
VASC   0.05%
DF     0.02%
```

### ğŸ¯ Next Steps

1. **View Full Documentation**: [README_EN.md](README_EN.md)
2. **Learn Model Details**: [MODEL_DOWNLOAD_GUIDE.md](MODEL_DOWNLOAD_GUIDE.md)
3. **Complete Tutorial**: [COMPLETE_TUTORIAL.md](COMPLETE_TUTORIAL.md)
4. **SOTA Comparison**: [COMPARISON_WITH_SOTA_EN.md](COMPARISON_WITH_SOTA_EN.md)

### ğŸ’¡ Tips

- **Recommended: Use HAM10000 model**: 98.90% accuracy, best performance
- **GPU Acceleration**: Using GPU significantly improves inference speed
- **Batch Processing**: Process multiple images at once for better efficiency

### ğŸ“ Need Help?

- **Documentation**: See [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)
- **Issues**: Submit [GitHub Issue](https://github.com/HeroZyy/skin-lesion-classification/issues)
- **Email**: a1048666899@gmail.com

---

<div align="center">

**Made with â¤ï¸ for advancing medical AI**

**ç”¨ â¤ï¸ æ¨è¿›åŒ»å­¦äººå·¥æ™ºèƒ½**

[â¬† Back to Top](#å¿«é€Ÿå¼€å§‹æŒ‡å—--quick-start-guide)

</div>


