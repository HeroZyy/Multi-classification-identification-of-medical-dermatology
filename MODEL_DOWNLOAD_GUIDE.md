# é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ä¸‹è½½æŒ‡å— / Pre-trained Model & Dataset Download Guide

<div align="right">
  <strong>ä¸­æ–‡</strong> | <a href="#english-version">English</a>
</div>

---

## ä¸­æ–‡ç‰ˆ

### ğŸ“¦ ä¸‹è½½èµ„æº

æˆ‘ä»¬æä¾›äº†åœ¨BCN20000å’ŒHAM10000æ•°æ®é›†ä¸Šè®­ç»ƒçš„é«˜æ€§èƒ½é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»¥åŠå®Œæ•´çš„æ•°æ®é›†ã€‚

**ğŸ”— Google Driveä¸‹è½½é“¾æ¥**: [https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q](https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q)

**åŒ…å«å†…å®¹**:
- âœ… é¢„è®­ç»ƒæ¨¡å‹ (4ä¸ª.pthæ–‡ä»¶)
- âœ… BCN20000æ•°æ®é›† (19,424å¼ å›¾åƒ)
- âœ… HAM10000æ•°æ®é›† (10,015å¼ å›¾åƒ)

---

## ğŸ“Š æ•°æ®é›†ä¸‹è½½

### å¯ç”¨æ•°æ®é›†

| æ•°æ®é›† | å›¾åƒæ•°é‡ | ç±»åˆ«æ•° | æ–‡ä»¶å¤§å° | è¯´æ˜ |
|--------|---------|--------|---------|------|
| **BCN20000** | 19,424 | 7 | ~2.5GB | å·´å¡ç½—é‚£åŒ»é™¢æ•°æ®é›† |
| **HAM10000** | 10,015 | 7 | ~1.8GB | äººç±»vsæœºå™¨æ•°æ®é›† |

### ğŸš€ æ•°æ®é›†å®‰è£…æ­¥éª¤

#### æ­¥éª¤1: ä¸‹è½½æ•°æ®é›†

1. è®¿é—®Google Driveé“¾æ¥
2. ä¸‹è½½ `BCN20000.zip` å’Œ `HAM10000.zip`
3. ä¿å­˜åˆ°æœ¬åœ°

#### æ­¥éª¤2: åˆ›å»ºç›®å½•ç»“æ„

åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºæ•°æ®é›†ç›®å½•ï¼š

```bash
mkdir -p linux_sub/app/datasets
```

#### æ­¥éª¤3: è§£å‹æ•°æ®é›†

å°†ä¸‹è½½çš„æ•°æ®é›†è§£å‹åˆ° `linux_sub/app/datasets/` ç›®å½•ï¼š

```
linux_sub/app/datasets/
â”œâ”€â”€ BCN20000/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ ISIC_0000001.jpg
â”‚   â”‚   â”œâ”€â”€ ISIC_0000002.jpg
â”‚   â”‚   â””â”€â”€ ... (19,424å¼ å›¾åƒ)
â”‚   â””â”€â”€ metadata.csv
â””â”€â”€ HAM10000/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ ISIC_0024306.jpg
    â”‚   â”œâ”€â”€ ISIC_0024307.jpg
    â”‚   â””â”€â”€ ... (10,015å¼ å›¾åƒ)
    â””â”€â”€ metadata.csv
```

### ğŸ“‹ æ•°æ®é›†æ ¼å¼

#### å…ƒæ•°æ®æ–‡ä»¶ (metadata.csv)

```csv
image_id,diagnosis,age,sex,localization
ISIC_0000001,NV,45,male,back
ISIC_0000002,MEL,60,female,face
ISIC_0000003,BKL,55,female,chest
```

**å­—æ®µè¯´æ˜**:
- `image_id`: å›¾åƒæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
- `diagnosis`: è¯Šæ–­ç±»åˆ«ï¼ˆNV, MEL, BKL, BCC, AKIEC, VASC, DFï¼‰
- `age`: æ‚£è€…å¹´é¾„
- `sex`: æ€§åˆ«ï¼ˆmale/femaleï¼‰
- `localization`: ç—…å˜ä½ç½®

#### ç±»åˆ«è¯´æ˜

| ä»£ç  | è‹±æ–‡åç§° | ä¸­æ–‡åç§° | ç±»å‹ | BCNæ•°é‡ | HAMæ•°é‡ |
|------|---------|---------|------|---------|---------|
| **NV** | Melanocytic Nevi | è‰¯æ€§ç—£ | è‰¯æ€§ | 12,875 | 6,705 |
| **MEL** | Melanoma | é»‘è‰²ç´ ç˜¤ | âš ï¸ æ¶æ€§ | 3,323 | 1,113 |
| **BKL** | Benign Keratosis | è‰¯æ€§è§’åŒ–ç—… | è‰¯æ€§ | 2,624 | 1,099 |
| **BCC** | Basal Cell Carcinoma | åŸºåº•ç»†èƒç™Œ | æ¶æ€§ | 514 | 514 |
| **AKIEC** | Actinic Keratoses | å…‰åŒ–æ€§è§’åŒ–ç—… | ç™Œå‰ | 67 | 327 |
| **VASC** | Vascular Lesions | è¡€ç®¡ç—…å˜ | è‰¯æ€§ | 15 | 142 |
| **DF** | Dermatofibroma | çš®è‚¤çº¤ç»´ç˜¤ | è‰¯æ€§ | 6 | 115 |

### ğŸ’» ä½¿ç”¨æ•°æ®é›†

#### åŠ è½½æ•°æ®é›†ç¤ºä¾‹

```python
import pandas as pd
from PIL import Image
import os

# åŠ è½½å…ƒæ•°æ®
metadata = pd.read_csv('linux_sub/app/datasets/BCN20000/metadata.csv')

# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
print(f"æ€»å›¾åƒæ•°: {len(metadata)}")
print(f"ç±»åˆ«åˆ†å¸ƒ:\n{metadata['diagnosis'].value_counts()}")

# åŠ è½½å•å¼ å›¾åƒ
image_id = metadata.iloc[0]['image_id']
image_path = f'linux_sub/app/datasets/BCN20000/images/{image_id}.jpg'
image = Image.open(image_path)
print(f"å›¾åƒå°ºå¯¸: {image.size}")
```

---

## ğŸ”§ é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½

### ğŸ“‹ å¯ç”¨æ¨¡å‹

| æ¨¡å‹æ–‡ä»¶ | æ•°æ®é›† | å‡†ç¡®ç‡ | MEL F1 | æ–‡ä»¶å¤§å° | è¯´æ˜ |
|---------|--------|--------|--------|---------|------|
| `BCN20000_best_model.pth` | BCN20000 | 93.33% | 0.974 | ~350MB | æœ€ä½³éªŒè¯æ€§èƒ½ |
| `HAM10000_best_model.pth` | HAM10000 | **98.90%** | **0.977** | ~350MB | **æ¨èä½¿ç”¨** â­ |
| `BCN20000_final_model.pth` | BCN20000 | 93.33% | 0.974 | ~350MB | æœ€ç»ˆè®­ç»ƒæ¨¡å‹ |
| `HAM10000_final_model.pth` | HAM10000 | 98.90% | 0.977 | ~350MB | æœ€ç»ˆè®­ç»ƒæ¨¡å‹ |

### ğŸš€ å®‰è£…æ­¥éª¤

#### æ­¥éª¤1: ä¸‹è½½æ¨¡å‹

1. è®¿é—®Google Driveé“¾æ¥
2. é€‰æ‹©éœ€è¦çš„æ¨¡å‹æ–‡ä»¶
3. ç‚¹å‡»ä¸‹è½½ï¼ˆæˆ–æ·»åŠ åˆ°æ‚¨çš„Google Driveåä¸‹è½½ï¼‰

#### æ­¥éª¤2: åˆ›å»ºç›®å½•ç»“æ„

åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºä»¥ä¸‹ç›®å½•ç»“æ„ï¼š

```bash
mkdir -p linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch
```

#### æ­¥éª¤3: æ”¾ç½®æ¨¡å‹æ–‡ä»¶

å°†ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶æ”¾ç½®åˆ°ä»¥ä¸‹ç›®å½•ï¼š

```
linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch/
â”œâ”€â”€ BCN20000_best_model.pth
â”œâ”€â”€ HAM10000_best_model.pth
â”œâ”€â”€ BCN20000_final_model.pth
â””â”€â”€ HAM10000_final_model.pth
```

### ğŸ’» ä½¿ç”¨æ–¹æ³•

#### æ–¹æ³•1: ä½¿ç”¨ModelLoaderï¼ˆæ¨èï¼‰

```python
from models.model_loader import ModelLoader

# åˆå§‹åŒ–åŠ è½½å™¨
loader = ModelLoader()

# åŠ è½½HAM10000æœ€ä½³æ¨¡å‹ï¼ˆæ¨èï¼‰
model = loader.load_swin_dual_model("HAM10000", best=True)

# æˆ–åŠ è½½BCN20000æœ€ä½³æ¨¡å‹
# model = loader.load_swin_dual_model("BCN20000", best=True)

# è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()
```

#### æ–¹æ³•2: ç›´æ¥åŠ è½½

```python
import torch
from models.swin_dual_branch import SwinDualBranchAttentionModel

# åˆ›å»ºæ¨¡å‹
model = SwinDualBranchAttentionModel(num_classes=7)

# åŠ è½½æƒé‡
checkpoint = torch.load(
    'linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch/HAM10000_best_model.pth',
    map_location='cpu'
)
model.load_state_dict(checkpoint['model_state_dict'])

# è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()
```

### ğŸ” å®Œæ•´æ¨ç†ç¤ºä¾‹

```python
import torch
from PIL import Image
from torchvision import transforms
from models.model_loader import ModelLoader

# 1. åŠ è½½æ¨¡å‹
loader = ModelLoader()
model = loader.load_swin_dual_model("HAM10000", best=True)
model.eval()

# 2. å‡†å¤‡å›¾åƒ
image_path = "path/to/your/skin_lesion_image.jpg"
image = Image.open(image_path).convert('RGB')

# 3. å›¾åƒé¢„å¤„ç†
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
image_tensor = transform(image).unsqueeze(0)

# 4. æ¨ç†
with torch.no_grad():
    output = model(image_tensor)
    probabilities = torch.softmax(output, dim=1)
    prediction = output.argmax(dim=1).item()
    confidence = probabilities.max().item()

# 5. è§£æç»“æœ
class_names = ['NV', 'MEL', 'BKL', 'BCC', 'AKIEC', 'VASC', 'DF']
class_descriptions = {
    'NV': 'è‰¯æ€§ç—£ (Melanocytic Nevi)',
    'MEL': 'é»‘è‰²ç´ ç˜¤ (Melanoma)',
    'BKL': 'è‰¯æ€§è§’åŒ–ç—… (Benign Keratosis)',
    'BCC': 'åŸºåº•ç»†èƒç™Œ (Basal Cell Carcinoma)',
    'AKIEC': 'å…‰åŒ–æ€§è§’åŒ–ç—… (Actinic Keratoses)',
    'VASC': 'è¡€ç®¡ç—…å˜ (Vascular Lesions)',
    'DF': 'çš®è‚¤çº¤ç»´ç˜¤ (Dermatofibroma)'
}

predicted_class = class_names[prediction]
print(f"é¢„æµ‹ç±»åˆ«: {predicted_class}")
print(f"ç±»åˆ«æè¿°: {class_descriptions[predicted_class]}")
print(f"ç½®ä¿¡åº¦: {confidence:.2%}")
print(f"\næ‰€æœ‰ç±»åˆ«æ¦‚ç‡:")
for i, (name, prob) in enumerate(zip(class_names, probabilities[0])):
    print(f"  {name}: {prob:.2%}")
```

### ğŸ“Š æ¨¡å‹æ€§èƒ½

#### HAM10000æ•°æ®é›†ï¼ˆæ¨èï¼‰

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»ä½“å‡†ç¡®ç‡ | **98.90%** ğŸ† |
| Macro F1 | 0.984 |
| Weighted F1 | 0.989 |
| é»‘è‰²ç´ ç˜¤F1 | **0.977** |

#### BCN20000æ•°æ®é›†

| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ€»ä½“å‡†ç¡®ç‡ | 93.33% |
| Macro F1 | 0.930 |
| Weighted F1 | 0.936 |
| é»‘è‰²ç´ ç˜¤F1 | 0.974 |

### âš™ï¸ ç³»ç»Ÿè¦æ±‚

- **Python**: 3.8+
- **PyTorch**: 2.0+
- **GPU**: æ¨èä½¿ç”¨GPUï¼ˆè‡³å°‘4GBæ˜¾å­˜ï¼‰
- **CPU**: ä¹Ÿå¯ä½¿ç”¨CPUæ¨ç†ï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰
- **å†…å­˜**: è‡³å°‘8GB RAM

### ğŸ”§ æ•…éšœæ’é™¤

#### é—®é¢˜1: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶

**é”™è¯¯ä¿¡æ¯**: `FileNotFoundError: [Errno 2] No such file or directory`

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½
- æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®
- ç¡®ä¿ç›®å½•ç»“æ„ä¸ä¸Šè¿°ä¸€è‡´

#### é—®é¢˜2: CUDAå†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯**: `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```python
# ä½¿ç”¨CPUæ¨ç†
model = model.to('cpu')
image_tensor = image_tensor.to('cpu')

# æˆ–å‡å°batch size
```

#### é—®é¢˜3: æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯ä¿¡æ¯**: `RuntimeError: Error(s) in loading state_dict`

**è§£å†³æ–¹æ¡ˆ**:
- ç¡®è®¤ä¸‹è½½çš„æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼ˆæœªæŸåï¼‰
- æ£€æŸ¥PyTorchç‰ˆæœ¬å…¼å®¹æ€§
- é‡æ–°ä¸‹è½½æ¨¡å‹æ–‡ä»¶

### ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»ï¼š
- **Email**: a1048666899@gmail.com
- **GitHub Issues**: [æäº¤é—®é¢˜](https://github.com/HeroZyy/skin-lesion-classification/issues)

---

<div id="english-version"></div>

## English Version

### ğŸ“¦ Download Resources

We provide high-performance pre-trained models trained on BCN20000 and HAM10000 datasets, along with the complete datasets.

**ğŸ”— Google Drive Download Link**: [https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q](https://drive.google.com/drive/folders/1oT9YuW5HMMYZdw5kzt8hj1aeVMR4Cm8q)

**Contents**:
- âœ… Pre-trained models (4 .pth files)
- âœ… BCN20000 dataset (19,424 images)
- âœ… HAM10000 dataset (10,015 images)

---

## ğŸ“Š Dataset Download

### Available Datasets

| Dataset | Images | Classes | File Size | Description |
|---------|--------|---------|-----------|-------------|
| **BCN20000** | 19,424 | 7 | ~2.5GB | Barcelona Hospital Clinic dataset |
| **HAM10000** | 10,015 | 7 | ~1.8GB | Human Against Machine dataset |

### ğŸš€ Dataset Installation Steps

#### Step 1: Download Datasets

1. Visit the Google Drive link
2. Download `BCN20000.zip` and `HAM10000.zip`
3. Save to local storage

#### Step 2: Create Directory Structure

Create the datasets directory in your project root:

```bash
mkdir -p linux_sub/app/datasets
```

#### Step 3: Extract Datasets

Extract the downloaded datasets to `linux_sub/app/datasets/`:

```
linux_sub/app/datasets/
â”œâ”€â”€ BCN20000/
â”‚   â”œâ”€â”€ images/
â”‚   â”‚   â”œâ”€â”€ ISIC_0000001.jpg
â”‚   â”‚   â”œâ”€â”€ ISIC_0000002.jpg
â”‚   â”‚   â””â”€â”€ ... (19,424 images)
â”‚   â””â”€â”€ metadata.csv
â””â”€â”€ HAM10000/
    â”œâ”€â”€ images/
    â”‚   â”œâ”€â”€ ISIC_0024306.jpg
    â”‚   â”œâ”€â”€ ISIC_0024307.jpg
    â”‚   â””â”€â”€ ... (10,015 images)
    â””â”€â”€ metadata.csv
```

### ğŸ“‹ Dataset Format

#### Metadata File (metadata.csv)

```csv
image_id,diagnosis,age,sex,localization
ISIC_0000001,NV,45,male,back
ISIC_0000002,MEL,60,female,face
ISIC_0000003,BKL,55,female,chest
```

**Field Descriptions**:
- `image_id`: Image filename (without extension)
- `diagnosis`: Diagnosis class (NV, MEL, BKL, BCC, AKIEC, VASC, DF)
- `age`: Patient age
- `sex`: Gender (male/female)
- `localization`: Lesion location

#### Class Descriptions

| Code | English Name | Type | BCN Count | HAM Count |
|------|-------------|------|-----------|-----------|
| **NV** | Melanocytic Nevi | Benign | 12,875 | 6,705 |
| **MEL** | Melanoma | âš ï¸ Malignant | 3,323 | 1,113 |
| **BKL** | Benign Keratosis | Benign | 2,624 | 1,099 |
| **BCC** | Basal Cell Carcinoma | Malignant | 514 | 514 |
| **AKIEC** | Actinic Keratoses | Pre-cancerous | 67 | 327 |
| **VASC** | Vascular Lesions | Benign | 15 | 142 |
| **DF** | Dermatofibroma | Benign | 6 | 115 |

### ğŸ’» Using the Dataset

#### Loading Dataset Example

```python
import pandas as pd
from PIL import Image
import os

# Load metadata
metadata = pd.read_csv('linux_sub/app/datasets/BCN20000/metadata.csv')

# View dataset info
print(f"Total images: {len(metadata)}")
print(f"Class distribution:\n{metadata['diagnosis'].value_counts()}")

# Load a single image
image_id = metadata.iloc[0]['image_id']
image_path = f'linux_sub/app/datasets/BCN20000/images/{image_id}.jpg'
image = Image.open(image_path)
print(f"Image size: {image.size}")
```

---

## ğŸ”§ Pre-trained Model Download

### ğŸ“‹ Available Models

| Model File | Dataset | Accuracy | MEL F1 | File Size | Description |
|-----------|---------|----------|--------|-----------|-------------|
| `BCN20000_best_model.pth` | BCN20000 | 93.33% | 0.974 | ~350MB | Best validation performance |
| `HAM10000_best_model.pth` | HAM10000 | **98.90%** | **0.977** | ~350MB | **Recommended** â­ |
| `BCN20000_final_model.pth` | BCN20000 | 93.33% | 0.974 | ~350MB | Final trained model |
| `HAM10000_final_model.pth` | HAM10000 | 98.90% | 0.977 | ~350MB | Final trained model |

### ğŸš€ Installation Steps

#### Step 1: Download Models

1. Visit the Google Drive link
2. Select the model files you need
3. Click download (or add to your Google Drive then download)

#### Step 2: Create Directory Structure

Create the following directory structure in your project root:

```bash
mkdir -p linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch
```

#### Step 3: Place Model Files

Place the downloaded model files in the following directory:

```
linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch/
â”œâ”€â”€ BCN20000_best_model.pth
â”œâ”€â”€ HAM10000_best_model.pth
â”œâ”€â”€ BCN20000_final_model.pth
â””â”€â”€ HAM10000_final_model.pth
```

### ğŸ’» Usage

#### Method 1: Using ModelLoader (Recommended)

```python
from models.model_loader import ModelLoader

# Initialize loader
loader = ModelLoader()

# Load HAM10000 best model (recommended)
model = loader.load_swin_dual_model("HAM10000", best=True)

# Or load BCN20000 best model
# model = loader.load_swin_dual_model("BCN20000", best=True)

# Set to evaluation mode
model.eval()
```

#### Method 2: Direct Loading

```python
import torch
from models.swin_dual_branch import SwinDualBranchAttentionModel

# Create model
model = SwinDualBranchAttentionModel(num_classes=7)

# Load weights
checkpoint = torch.load(
    'linux_sub/app/models/five_model_comparison_final/models/swin_dual_branch/HAM10000_best_model.pth',
    map_location='cpu'
)
model.load_state_dict(checkpoint['model_state_dict'])

# Set to evaluation mode
model.eval()
```

### ğŸ” Complete Inference Example

```python
import torch
from PIL import Image
from torchvision import transforms
from models.model_loader import ModelLoader

# 1. Load model
loader = ModelLoader()
model = loader.load_swin_dual_model("HAM10000", best=True)
model.eval()

# 2. Prepare image
image_path = "path/to/your/skin_lesion_image.jpg"
image = Image.open(image_path).convert('RGB')

# 3. Image preprocessing
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])
image_tensor = transform(image).unsqueeze(0)

# 4. Inference
with torch.no_grad():
    output = model(image_tensor)
    probabilities = torch.softmax(output, dim=1)
    prediction = output.argmax(dim=1).item()
    confidence = probabilities.max().item()

# 5. Parse results
class_names = ['NV', 'MEL', 'BKL', 'BCC', 'AKIEC', 'VASC', 'DF']
class_descriptions = {
    'NV': 'Melanocytic Nevi (Benign Mole)',
    'MEL': 'Melanoma (Malignant)',
    'BKL': 'Benign Keratosis',
    'BCC': 'Basal Cell Carcinoma',
    'AKIEC': 'Actinic Keratoses',
    'VASC': 'Vascular Lesions',
    'DF': 'Dermatofibroma'
}

predicted_class = class_names[prediction]
print(f"Predicted Class: {predicted_class}")
print(f"Description: {class_descriptions[predicted_class]}")
print(f"Confidence: {confidence:.2%}")
print(f"\nAll Class Probabilities:")
for i, (name, prob) in enumerate(zip(class_names, probabilities[0])):
    print(f"  {name}: {prob:.2%}")
```

### ğŸ“Š Model Performance

#### HAM10000 Dataset (Recommended)

| Metric | Value |
|--------|-------|
| Overall Accuracy | **98.90%** ğŸ† |
| Macro F1 | 0.984 |
| Weighted F1 | 0.989 |
| Melanoma F1 | **0.977** |

#### BCN20000 Dataset

| Metric | Value |
|--------|-------|
| Overall Accuracy | 93.33% |
| Macro F1 | 0.930 |
| Weighted F1 | 0.936 |
| Melanoma F1 | 0.974 |

### âš™ï¸ System Requirements

- **Python**: 3.8+
- **PyTorch**: 2.0+
- **GPU**: Recommended (at least 4GB VRAM)
- **CPU**: Can also use CPU inference (slower)
- **RAM**: At least 8GB

### ğŸ”§ Troubleshooting

#### Issue 1: Model File Not Found

**Error Message**: `FileNotFoundError: [Errno 2] No such file or directory`

**Solution**:
- Confirm model files are downloaded
- Check file path is correct
- Ensure directory structure matches above

#### Issue 2: CUDA Out of Memory

**Error Message**: `RuntimeError: CUDA out of memory`

**Solution**:
```python
# Use CPU inference
model = model.to('cpu')
image_tensor = image_tensor.to('cpu')

# Or reduce batch size
```

#### Issue 3: Model Loading Failed

**Error Message**: `RuntimeError: Error(s) in loading state_dict`

**Solution**:
- Confirm downloaded model file is complete (not corrupted)
- Check PyTorch version compatibility
- Re-download model file

### ğŸ“ Technical Support

For questions, please contact:
- **Email**: a1048666899@gmail.com
- **GitHub Issues**: [Submit Issue](https://github.com/HeroZyy/skin-lesion-classification/issues)

---

<div align="center">

**Made with â¤ï¸ for advancing medical AI**

**ç”¨ â¤ï¸ æ¨è¿›åŒ»å­¦äººå·¥æ™ºèƒ½**

[â¬† Back to Top](#é¢„è®­ç»ƒæ¨¡å‹ä¸‹è½½æŒ‡å—--pre-trained-model-download-guide)

</div>


